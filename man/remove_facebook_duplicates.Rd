% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/misc.R
\name{remove_facebook_duplicates}
\alias{remove_facebook_duplicates}
\title{Clean Facebook data duplicates}
\usage{
remove_facebook_duplicates(
  dir,
  file,
  sort = c("created_time", "scrape_time", "id"),
  sort_direction = c("desc", "desc", "asc")
)
}
\arguments{
\item{dir}{A path to a directory containing Facebook data files.}

\item{file}{A file path to one Facebook data file (as rds file).}

\item{sort}{Data is sorted by these variable(s). Defaults to
c("created_time", "scrape_time", "id") to sort data by these variables.
The sort is applied before duplicates are removed. Therefore by default
newer data (by scrape_time) is kept.}

\item{sort_direction}{Sort parameters are applied in this directions. Should
be length 1 (all parameters are sorted this way) or the same length as
sort. Possible values are "desc" for descending and "asc" or "" for
ascending. Defaults to c("desc", "desc", "asc"). Thus, by default,
created_time is sorted descendingly, posts with the same created_time are
sorted descendingly by scrape_time and then ascendingly by message id.}
}
\description{
Somehow duplicates ended up in the data, where the same post is stored with
two different message IDs. Here, only messages where the sender (from_id),
message text (message), time of the posting (created_time), and message type
(type) are distinct are kept. You can provide either a directory or a file.
}
